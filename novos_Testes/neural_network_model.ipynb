{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b432d5e7",
   "metadata": {},
   "source": [
    "# Neural Network (PyTorch) - HepG2 Cryoprotectant Optimization\n",
    "\n",
    "Rede neural simples com PyTorch otimizada para datasets pequenos (regularização + early stopping)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23feac00",
   "metadata": {},
   "source": [
    "## Importar bibliotecas e configurar constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32e32101",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, torch, torch.nn as nn\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "BASE_DIR = Path('..').resolve()\n",
    "FEATURES, TARGET = ['% DMSO', 'TREHALOSE'], '% QUEDA DA VIABILIDADE'\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "378f5716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 200 samples | Train: 160 | Test: 40\n",
      "Viability drop: 0.15% - 100.00% (mean: 45.10%)\n"
     ]
    }
   ],
   "source": [
    "def safe_float(x):\n",
    "    s = str(x).replace('%', '').replace(',', '.').strip()\n",
    "    return float('nan') if s in ('', 'nan') else float(s)\n",
    "\n",
    "df = pd.read_csv(BASE_DIR / 'data/raw/hepg2.csv', decimal=',', thousands='.')\n",
    "for col in FEATURES + [TARGET]:\n",
    "    df[col] = df[col].apply(safe_float)\n",
    "\n",
    "df = df.dropna(subset=FEATURES + [TARGET])\n",
    "df = df[~((df[FEATURES[0]] == 0) & (df[FEATURES[1]] == 0))]\n",
    "df = df[((df[FEATURES] >= 0).all(axis=1)) & ((df[FEATURES] <= 100).all(axis=1))]\n",
    "\n",
    "X, y = df[FEATURES].values, df[TARGET].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train_t = torch.FloatTensor(X_train).to(device)\n",
    "y_train_t = torch.FloatTensor(y_train.reshape(-1, 1)).to(device)\n",
    "X_test_t = torch.FloatTensor(X_test).to(device)\n",
    "y_test_t = torch.FloatTensor(y_test.reshape(-1, 1)).to(device)\n",
    "\n",
    "print(f\"Dataset: {len(df)} samples | Train: {len(X_train)} | Test: {len(X_test)}\")\n",
    "print(f\"Viability drop: {y.min():.2f}% - {y.max():.2f}% (mean: {y.mean():.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad710c10",
   "metadata": {},
   "source": [
    "## Carregar e preparar dados\n",
    "\n",
    "Leitura do CSV com conversão de valores percentuais e decimais em virgula. Limpeza de valores ausentes, normalização com StandardScaler e conversão para tensores PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c28472",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(2, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(16, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "model = SimpleNN().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.001)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "best_test_loss = float('inf')\n",
    "patience, patience_counter = 50, 0\n",
    "\n",
    "for epoch in range(500):\n",
    "    model.train()\n",
    "    y_pred = model(X_train_t)\n",
    "    loss = loss_fn(y_pred, y_train_t)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_loss = loss_fn(model(X_test_t), y_test_t).item()\n",
    "            if test_loss < best_test_loss:\n",
    "                best_test_loss = test_loss\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                break\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_train = model(X_train_t).cpu().numpy()\n",
    "    y_pred_test = model(X_test_t).cpu().numpy()\n",
    "\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "mae = mean_absolute_error(y_test, y_pred_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"NEURAL NETWORK PERFORMANCE\")\n",
    "print(\"=\"*50)\n",
    "print(f\"R² (Train): {r2_train:.4f} | R² (Test): {r2_test:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}% | RMSE: {rmse:.4f}%\")\n",
    "print(f\"Epochs trained: {epoch+1} (early stopped at patience={patience_counter})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ad58d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "conc = np.arange(0, 101, 1)\n",
    "grid = np.array(np.meshgrid(conc, conc)).reshape(2, -1).T\n",
    "grid_scaled = scaler.transform(grid)\n",
    "grid_t = torch.FloatTensor(grid_scaled).to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(grid_t).cpu().numpy().flatten()\n",
    "\n",
    "valid = ~((grid[:, 0] == 0) & (grid[:, 1] == 0))\n",
    "best_idx = np.argmin(y_pred[valid])\n",
    "best_global_idx = np.where(valid)[0][best_idx]\n",
    "\n",
    "best_dmso, best_tre = grid[best_global_idx]\n",
    "best_viab = 100 - y_pred[best_global_idx]\n",
    "\n",
    "top_idx = np.argsort(y_pred[valid])[:15]\n",
    "top_global = np.where(valid)[0][top_idx]\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"OPTIMAL RECOMMENDATION\")\n",
    "print(\"=\"*50)\n",
    "print(f\"DMSO: {best_dmso:.0f}% | Trehalose: {best_tre:.0f}%\")\n",
    "print(f\"Predicted Viability: {best_viab:.2f}%\")\n",
    "print(\"\\nTOP 15 COMBINATIONS:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Rank':>4} {'DMSO':>7} {'Trehalose':>11} {'Viability':>12}\")\n",
    "print(\"-\" * 60)\n",
    "for i, idx in enumerate(top_global, 1):\n",
    "    d, t = grid[idx]\n",
    "    v = 100 - y_pred[idx]\n",
    "    print(f\"{i:4d} {d:6.0f}% {t:10.0f}% {v:11.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107fb244",
   "metadata": {},
   "source": [
    "## Gerar predições para grid de combinações\n",
    "\n",
    "Avalia todas as combinações de concentração (0-100%) em passos de 1%. Identifica as top 15 combinações com melhor predição de viabilidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41ad43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_obs_idx = df[TARGET].argmin()\n",
    "best_obs = df.iloc[best_obs_idx]\n",
    "best_obs_viab = 100 - best_obs[TARGET]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPARISON: Neural Network vs Dataset Observed\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nDataset Best Observed:\")\n",
    "print(f\"   DMSO: {best_obs[FEATURES[0]]:.0f}% | Trehalose: {best_obs[FEATURES[1]]:.0f}%\")\n",
    "print(f\"   Viability: {best_obs_viab:.2f}% (actual measurement)\")\n",
    "\n",
    "print(f\"\\nNeural Network Recommendation:\")\n",
    "print(f\"   DMSO: {best_dmso:.0f}% | Trehalose: {best_tre:.0f}%\")\n",
    "print(f\"   Predicted Viability: {best_viab:.2f}%\")\n",
    "\n",
    "test_best = torch.FloatTensor(scaler.transform(np.array([[best_obs[FEATURES[0]], best_obs[FEATURES[1]]]]))).to(device)\n",
    "with torch.no_grad():\n",
    "    nn_pred_for_best = 100 - model(test_best).cpu().item()\n",
    "print(f\"\\n   NN prediction for observed best: {nn_pred_for_best:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4045fe",
   "metadata": {},
   "source": [
    "## Comparar predição com observações do dataset\n",
    "\n",
    "Valida se a recomendação do modelo está alinhada com os melhores casos realmente observados nos dados experimentais."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
